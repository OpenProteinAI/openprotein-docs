---
title: Embeddings
format:
  html:
    code-fold: true
    include-in-header: 
      - shared/api-header.html
---

The Embeddings API provided by OpenProtein.ai allows you to generate state-of-the-art protein sequence embeddings from both proprietary and open source models. <br/>\nYou can list the available models with `/embeddings/models` and view a model summary (including output dimensions, citations and more) with `/embeddings/model/metadata`. <br/>

Currently, we support the following models:

* **Prot-seq**: A proprietary Masked protein language model (~300M parameters) trained on UniRef50 with contact and secondary structure prediction as secondary objectives. This model utilizes random Fourier position embeddings and FlashAttention to enable fast inference. It has a max sequence length of 1024, with dimension 1024. It supports **attn**, **embed**, **logits** as output types.
* **Rotaprot-large-uniref50w**: A proprietary Masked protein language model (~900M parameters) trained on UniRef100 with sequences weighted inversely proportional to the number of UniRef50 homologs. This model uses rotary relative position embeddings and FlashAttention to enable fast inference. It has a max sequence length of 1024, with dimension 1536. It supports **attn**, **embed**, **logits** as output types.
* **Rotaprot-large-uniref90-ft**: A version of our proprietary rotaprot-large-uniref50w finetuned on UniRef100 with sequences weighted inversely proportional to the number of UniRef90 cluster members. It has a max sequence length of 1024, with dimension 1536. It supports **attn**, **embed**, **logits** as output types.
* **ESM1 Models**: Community based ESM1 models, including: *esm1b_t33_650M_UR50S*, *esm1v_t33_650M_UR90S_1*, *esm1v_t33_650M_UR90S_2*, *esm1v_t33_650M_UR90S_3*, *esm1v_t33_650M_UR90S_4*, *esm1v_t33_650M_UR90S_5*.
These are based on the ESM1 language model, with different versions having different model parameters and training data. [More info](https://github.com/facebookresearch/esm){target="_blank"}.
* **ESM2 Models**: Community based ESM2 models, including: *esm2_t6_8M_UR50D*, *esm2_t12_35M_UR50D*, *esm2_t30_150M_UR50D*, *esm2_t33_650M_UR50D*. 
These models are based on the ESM2 language model, with different version having different model parameters and training data. [More info](https://github.com/facebookresearch/esm){target="_blank"}.

## Endpoints

```{=html}
<script type="module">
  import addSwaggerEndpointsToTOC from './js/addSwaggerEndpointsToTOC.js';
  import getSwaggerJson from "./js/getSwaggerJson.js";
  
  window.onload = async function() {
    // get swagerSpecs manipulated 
    const swagerSpecs = await getSwaggerJson('embeddings');
      
    const ui = SwaggerUIBundle({
      spec: swagerSpecs,
      dom_id: "#swagger-ui",
      config: {
        deepLinking: true,
        tagsSorter: "alpha",
        docExpansion: "list",
      },
      requestInterceptor: (request) => {
          const requestPath = request.url.split('/').slice(3).join('/')
          request.url = "https://dev.api.openprotein.ai/" + requestPath
       
        return request;
      },
    });
    addSwaggerEndpointsToTOC(0);
  };
</script>
<link rel="stylesheet" href="css/swagger-ui.css">
<div id="swagger-ui"></div>
```
